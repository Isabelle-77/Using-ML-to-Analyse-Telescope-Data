{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94074bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9278795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  u             g             r             i             z  \\\n",
      "count  99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
      "mean      22.080679     20.631583     19.645777     19.084865     18.768988   \n",
      "std        2.251068      2.037384      1.854763      1.757900      1.765982   \n",
      "min       10.996230     10.498200      9.822070      9.469903      9.612333   \n",
      "25%       20.352410     18.965240     18.135795     17.732280     17.460830   \n",
      "50%       22.179140     21.099930     20.125310     19.405150     19.004600   \n",
      "75%       23.687480     22.123775     21.044790     20.396510     19.921120   \n",
      "max       32.781390     31.602240     29.571860     32.141470     29.383740   \n",
      "\n",
      "           redshift  \n",
      "count  99999.000000  \n",
      "mean       0.576667  \n",
      "std        0.730709  \n",
      "min       -0.009971  \n",
      "25%        0.054522  \n",
      "50%        0.424176  \n",
      "75%        0.704172  \n",
      "max        7.011245  \n",
      "          u         g         r         i         z   class  redshift\n",
      "0  23.87882  22.27530  20.39501  19.16573  18.79371  GALAXY  0.634794\n",
      "1  24.77759  22.83188  22.58444  21.16812  21.61427  GALAXY  0.779136\n",
      "2  25.26307  22.66389  20.60976  19.34857  18.94827  GALAXY  0.644195\n",
      "3  22.13682  23.77656  21.61162  20.50454  19.25010  GALAXY  0.932346\n",
      "4  19.43718  17.58028  16.49747  15.97711  15.54461  GALAXY  0.116123\n",
      "5  23.48827  23.33776  21.32195  20.25615  19.54544     QSO  1.424659\n",
      "6  21.46973  21.17624  20.92829  20.60826  20.42573     QSO  0.586455\n",
      "7  22.24979  22.02172  20.34126  19.48794  18.84999  GALAXY  0.477009\n",
      "8  24.40286  22.35669  20.61032  19.46490  18.95852  GALAXY  0.660012\n",
      "9  21.74669  20.03493  19.17553  18.81823  18.65422    STAR -0.000008\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('star_classification.csv')\n",
    "#feature selection\n",
    "df = df.drop(['obj_ID','alpha','delta','run_ID','rerun_ID','cam_col','field_ID','spec_obj_ID','plate','MJD','fiber_ID'], axis='columns')\n",
    "\n",
    "#cleaning the data\n",
    "df = df[(df['u'] >= 0)]\n",
    "#df = df[(df['g'] >= 0)]\n",
    "#df = df[(df['z'] >= 0)]\n",
    "\n",
    "print(df.describe())\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b692d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning the Class values into categorical data\n",
    "df=df.rename(columns = {'class':'Class'})\n",
    "df.Class = df.Class.astype('category')\n",
    "cat_columns = df.select_dtypes(['category']).columns\n",
    "cat_columns\n",
    "df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de30ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 0 2 2 1 0 0]\n",
      "0.9443\n",
      "[[11294   486     8]\n",
      " [  258  3319     5]\n",
      " [  352     5  4273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     11788\n",
      "           1       0.87      0.93      0.90      3582\n",
      "           2       1.00      0.92      0.96      4630\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.94      0.94      0.94     20000\n",
      "weighted avg       0.95      0.94      0.94     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# raw data Log_Regression\n",
    "## train test split\n",
    "X = df.drop('Class',axis='columns')\n",
    "y = np.array(df['Class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state = 42)\n",
    "\n",
    "print(y_test[:10])\n",
    "\n",
    "#array dimensions\n",
    "y_train = y_train.transpose()\n",
    "y_test = y_test.transpose()\n",
    "\n",
    "# running Log_Regression with raw data\n",
    "lg_model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
    "lg_model = lg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lg_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb46bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'l1_ratio': 0.1, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.9299\n",
      "[[11264   492   256]\n",
      " [  227  3305     1]\n",
      " [  413    13  4029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     12012\n",
      "           1       0.87      0.94      0.90      3533\n",
      "           2       0.94      0.90      0.92      4455\n",
      "\n",
      "    accuracy                           0.93     20000\n",
      "   macro avg       0.92      0.93      0.92     20000\n",
      "weighted avg       0.93      0.93      0.93     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'solver': ['saga'],  #saga solver for multiclass and elasticnet\n",
    "    'l1_ratio': [0.1, 0.5, 0.7],\n",
    "    'max_iter': [500, 1000, 2000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lg_model, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=3, #cross validation\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1) \n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "lg_model = LogisticRegression()\n",
    "lg_model = lg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred = lg_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "184eee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          u         g         r         i         z  redshift  Class\n",
      "0  0.591347  0.558050  0.535344  0.427665  0.464377  0.091831      0\n",
      "1  0.632603  0.584423  0.646203  0.515986  0.607035  0.112389      0\n",
      "2  0.654888  0.576463  0.546218  0.435729  0.472194  0.093170      0\n",
      "3  0.511384  0.629186  0.596946  0.486717  0.487460  0.134210      0\n",
      "4  0.387463  0.335579  0.337999  0.287021  0.300043  0.017959      0\n",
      "5  0.573420  0.608393  0.582279  0.475761  0.502398  0.204328      1\n",
      "6  0.480763  0.505971  0.562346  0.491292  0.546921  0.084946      1\n",
      "7  0.516570  0.546034  0.532623  0.441877  0.467223  0.069358      0\n",
      "8  0.615402  0.561906  0.546246  0.440860  0.472712  0.095423      0\n",
      "9  0.493476  0.451891  0.473598  0.412337  0.457321  0.001419      2\n",
      "                  u             g             r             i             z  \\\n",
      "count  99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
      "mean       0.508807      0.480163      0.497408      0.424098      0.463126   \n",
      "std        0.103330      0.096540      0.093913      0.077538      0.089320   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.429475      0.401205      0.420953      0.364438      0.396962   \n",
      "50%        0.513327      0.502355      0.521689      0.438225      0.475043   \n",
      "75%        0.582564      0.550870      0.568245      0.481952      0.521399   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "           redshift         Class  \n",
      "count  99999.000000  99999.000000  \n",
      "mean       0.083552      0.621476  \n",
      "std        0.104072      0.816771  \n",
      "min        0.000000      0.000000  \n",
      "25%        0.009185      0.000000  \n",
      "50%        0.061833      0.000000  \n",
      "75%        0.101712      1.000000  \n",
      "max        1.000000      2.000000  \n"
     ]
    }
   ],
   "source": [
    "#normalizing\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# normalize features\n",
    "scaler = preprocessing.MinMaxScaler()  #default range [0, 1]\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "#put everything together in a pandas dataframe, list\n",
    "X_normalized = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "df_normalized = pd.concat([X_normalized, y.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(df_normalized.head(10))\n",
    "print(df_normalized.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79f6f790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93795\n",
      "[[11291   487   125]\n",
      " [  223  3311     4]\n",
      " [  390    12  4157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     11903\n",
      "           1       0.87      0.94      0.90      3538\n",
      "           2       0.97      0.91      0.94      4559\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.93      0.93      0.93     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normalized data Log_Regression\n",
    "\n",
    "## train test split\n",
    "X = df_normalized.drop('Class',axis='columns')\n",
    "y = np.array(df_normalized['Class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state = 42)\n",
    "\n",
    "#array dimensions\n",
    "y_train = y_train.transpose()\n",
    "y_test = y_test.transpose()\n",
    "\n",
    "# running Log_Regression with normalized data\n",
    "lg_model = LogisticRegression(multi_class='multinomial', solver='saga', penalty='elasticnet', l1_ratio = 0.5, C=0.9)\n",
    "lg_model = lg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lg_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43bcfd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-2f6668e0a9d0>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Class'] = train['Class'].astype('category')\n",
      "<ipython-input-8-2f6668e0a9d0>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Class_code'] = train['Class'].cat.codes\n"
     ]
    }
   ],
   "source": [
    "#creating a subset of the training data\n",
    "\n",
    "train, test = train_test_split(df_normalized,test_size=0.2, random_state = 42)\n",
    "\n",
    "#subset the dataframe\n",
    "train['Class'] = train['Class'].astype('category')\n",
    "\n",
    "train['Class_code'] = train['Class'].cat.codes\n",
    "sub1 = train[train['Class_code'] == train['Class'].cat.categories.get_loc(1)]\n",
    "\n",
    "#creating a subset of galaxies sub0\n",
    "n_sub1 = len(sub1)\n",
    "sub0_all = train[train['Class_code'] == train['Class'].cat.categories.get_loc(0)]\n",
    "sub0 = sub0_all.sample(n=n_sub1, random_state=42)  \n",
    "\n",
    "#creating a subset of stars sub2\n",
    "sub2_all = train[train['Class_code'] == train['Class'].cat.categories.get_loc(2)]\n",
    "sub2 = sub2_all.sample(n=n_sub1, random_state=42)  \n",
    "\n",
    "#merge the subsets\n",
    "sub=pd.concat([sub0, sub1, sub2], axis=0)\n",
    "\n",
    "sub_shuffle = sub.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e45b295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8816\n",
      "[[9872  306   10]\n",
      " [ 634 3485    1]\n",
      " [1398   19 4275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89     10188\n",
      "           1       0.91      0.85      0.88      4120\n",
      "           2       1.00      0.75      0.86      5692\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.91      0.86      0.88     20000\n",
      "weighted avg       0.89      0.88      0.88     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running Log_Regression with normalized and subseted data\n",
    "\n",
    "#train test split\n",
    "X_train = sub_shuffle.drop('Class',axis='columns')\n",
    "X_train = X_train.drop('Class_code',axis='columns')\n",
    "y_train = np.array(sub_shuffle['Class'])\n",
    "\n",
    "X_test = test.drop('Class',axis='columns')\n",
    "y_test = np.array(test['Class'])\n",
    "\n",
    "#array dimensions\n",
    "y_train = y_train.transpose()\n",
    "y_test = y_test.transpose()\n",
    "\n",
    "#running Log_Reg\n",
    "lg_model = LogisticRegression(multi_class='multinomial', solver='saga', penalty='elasticnet', l1_ratio = 0.5, C=0.9)\n",
    "lg_model = lg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lg_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
