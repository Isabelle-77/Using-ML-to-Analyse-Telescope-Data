{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4891921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabpfn in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (0.1.11)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from tabpfn) (5.4.1)\n",
      "Collecting torch>=1.9.0\n",
      "  Using cached torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl (150.6 MB)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from tabpfn) (2.25.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from tabpfn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from tabpfn) (1.22.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->tabpfn) (2024.8.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->tabpfn) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->tabpfn) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->tabpfn) (4.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24.2->tabpfn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.9.0->tabpfn) (2.11.3)\n",
      "Requirement already satisfied: filelock in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.9.0->tabpfn) (3.0.12)\n",
      "Requirement already satisfied: fsspec in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.9.0->tabpfn) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.9.0->tabpfn) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.9.0->tabpfn) (2.5)\n",
      "Requirement already satisfied: sympy in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.9.0->tabpfn) (1.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from jinja2->torch>=1.9.0->tabpfn) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from networkx->torch>=1.9.0->tabpfn) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ire/opt/anaconda3/lib/python3.8/site-packages (from sympy->torch>=1.9.0->tabpfn) (1.2.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94074bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807dc2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model\n",
    "clf = TabPFNClassifier(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9278795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  u             g             r             i             z  \\\n",
      "count  99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
      "mean      22.080679     20.631583     19.645777     19.084865     18.768988   \n",
      "std        2.251068      2.037384      1.854763      1.757900      1.765982   \n",
      "min       10.996230     10.498200      9.822070      9.469903      9.612333   \n",
      "25%       20.352410     18.965240     18.135795     17.732280     17.460830   \n",
      "50%       22.179140     21.099930     20.125310     19.405150     19.004600   \n",
      "75%       23.687480     22.123775     21.044790     20.396510     19.921120   \n",
      "max       32.781390     31.602240     29.571860     32.141470     29.383740   \n",
      "\n",
      "           redshift  \n",
      "count  99999.000000  \n",
      "mean       0.576667  \n",
      "std        0.730709  \n",
      "min       -0.009971  \n",
      "25%        0.054522  \n",
      "50%        0.424176  \n",
      "75%        0.704172  \n",
      "max        7.011245  \n",
      "          u         g         r         i         z   class  redshift\n",
      "0  23.87882  22.27530  20.39501  19.16573  18.79371  GALAXY  0.634794\n",
      "1  24.77759  22.83188  22.58444  21.16812  21.61427  GALAXY  0.779136\n",
      "2  25.26307  22.66389  20.60976  19.34857  18.94827  GALAXY  0.644195\n",
      "3  22.13682  23.77656  21.61162  20.50454  19.25010  GALAXY  0.932346\n",
      "4  19.43718  17.58028  16.49747  15.97711  15.54461  GALAXY  0.116123\n",
      "5  23.48827  23.33776  21.32195  20.25615  19.54544     QSO  1.424659\n",
      "6  21.46973  21.17624  20.92829  20.60826  20.42573     QSO  0.586455\n",
      "7  22.24979  22.02172  20.34126  19.48794  18.84999  GALAXY  0.477009\n",
      "8  24.40286  22.35669  20.61032  19.46490  18.95852  GALAXY  0.660012\n",
      "9  21.74669  20.03493  19.17553  18.81823  18.65422    STAR -0.000008\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('star_classification.csv')\n",
    "#feature selection\n",
    "df = df.drop(['obj_ID','alpha','delta','run_ID','rerun_ID','cam_col','field_ID','spec_obj_ID','plate','MJD','fiber_ID'], axis='columns')\n",
    "\n",
    "#cleaning the data\n",
    "df = df[(df['u'] >= 0)]\n",
    "#df = df[(df['g'] >= 0)]\n",
    "#df = df[(df['z'] >= 0)]\n",
    "\n",
    "print(df.describe())\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b692d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning the Class values into categorical data\n",
    "df=df.rename(columns = {'class':'Class'})\n",
    "df.Class = df.Class.astype('category')\n",
    "cat_columns = df.select_dtypes(['category']).columns\n",
    "cat_columns\n",
    "df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de30ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 0 0 1 0 2 2 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "[[110   1   0]\n",
      " [  1  43   0]\n",
      " [  2   0  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       111\n",
      "           1       0.98      0.98      0.98        44\n",
      "           2       1.00      0.96      0.98        45\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.98      0.97      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# raw data GradientBoostingClassifier\n",
    "## train test split\n",
    "df_sampled = df.sample(n=1000, random_state=42)\n",
    "\n",
    "X = df_sampled.drop('Class',axis='columns')\n",
    "y = np.array(df_sampled['Class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(y_test[:10])\n",
    "\n",
    "#array dimensions\n",
    "y_train = y_train.transpose()\n",
    "y_test = y_test.transpose()\n",
    "\n",
    "# Train the TabPFN model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d9def77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
    "print(torch.version.cuda)         # Check installed CUDA version\n",
    "print(torch.__version__)          # Check PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b90acc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/10...\n",
      "Processing batch 2/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 9/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 10/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961\n",
      "[[1128   37    5]\n",
      " [  15  376    0]\n",
      " [  19    2  418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1170\n",
      "           1       0.91      0.96      0.93       391\n",
      "           2       0.99      0.95      0.97       439\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.95      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sampled = df.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_sampled = df_sampled.drop('Class',axis='columns')\n",
    "y_sampled = np.array(df_sampled['Class'])\n",
    "\n",
    "batch_size = 1000\n",
    "num_batches = len(X_sampled) // batch_size\n",
    "\n",
    "# Initialize lists to store results\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Loop through batches\n",
    "for i in range(num_batches):\n",
    "    print(f\"Processing batch {i+1}/{num_batches}...\")\n",
    "\n",
    "    # Get batch indices\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "\n",
    "    # Extract batch\n",
    "    X_batch = X_sampled[start_idx:end_idx]\n",
    "    y_batch = y_sampled[start_idx:end_idx]\n",
    "\n",
    "    # Train-test split for this batch\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train TabPFN\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "    \n",
    "    \n",
    "print(accuracy_score(all_y_true, all_y_pred))\n",
    "print(metrics.confusion_matrix(all_y_pred, all_y_true))\n",
    "print(classification_report(all_y_pred, all_y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9578a1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          u         g         r         i         z  redshift  Class\n",
      "0  0.591347  0.558050  0.535344  0.427665  0.464377  0.091831      0\n",
      "1  0.632603  0.584423  0.646203  0.515986  0.607035  0.112389      0\n",
      "2  0.654888  0.576463  0.546218  0.435729  0.472194  0.093170      0\n",
      "3  0.511384  0.629186  0.596946  0.486717  0.487460  0.134210      0\n",
      "4  0.387463  0.335579  0.337999  0.287021  0.300043  0.017959      0\n",
      "5  0.573420  0.608393  0.582279  0.475761  0.502398  0.204328      1\n",
      "6  0.480763  0.505971  0.562346  0.491292  0.546921  0.084946      1\n",
      "7  0.516570  0.546034  0.532623  0.441877  0.467223  0.069358      0\n",
      "8  0.615402  0.561906  0.546246  0.440860  0.472712  0.095423      0\n",
      "9  0.493476  0.451891  0.473598  0.412337  0.457321  0.001419      2\n",
      "                  u             g             r             i             z  \\\n",
      "count  99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
      "mean       0.508807      0.480163      0.497408      0.424098      0.463126   \n",
      "std        0.103330      0.096540      0.093913      0.077538      0.089320   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.429475      0.401205      0.420953      0.364438      0.396962   \n",
      "50%        0.513327      0.502355      0.521689      0.438225      0.475043   \n",
      "75%        0.582564      0.550870      0.568245      0.481952      0.521399   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "           redshift         Class  \n",
      "count  99999.000000  99999.000000  \n",
      "mean       0.083552      0.621476  \n",
      "std        0.104072      0.816771  \n",
      "min        0.000000      0.000000  \n",
      "25%        0.009185      0.000000  \n",
      "50%        0.061833      0.000000  \n",
      "75%        0.101712      1.000000  \n",
      "max        1.000000      2.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py:1675: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they. (Deprecated NumPy 1.22)\n",
      "  return np.percentile(values, q, axis=axis, interpolation=interpolation)\n",
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py:1675: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they. (Deprecated NumPy 1.22)\n",
      "  return np.percentile(values, q, axis=axis, interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "#normalizing\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "#normalize features\n",
    "scaler = preprocessing.MinMaxScaler()  #default range [0, 1]\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "#put everything together in a pandas dataframe, list\n",
    "X_normalized = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "df_normalized = pd.concat([X_normalized, y.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(df_normalized.head(10))\n",
    "print(df_normalized.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a069a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/10...\n",
      "Processing batch 2/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 9/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 10/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ire/opt/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961\n",
      "[[1128   37    5]\n",
      " [  15  376    0]\n",
      " [  19    2  418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1170\n",
      "           1       0.91      0.96      0.93       391\n",
      "           2       0.99      0.95      0.97       439\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.95      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sampled = df_normalized.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_sampled = df_sampled.drop('Class',axis='columns')\n",
    "y_sampled = np.array(df_sampled['Class'])\n",
    "\n",
    "batch_size = 1000\n",
    "num_batches = len(X_sampled) // batch_size\n",
    "\n",
    "# Initialize lists to store results\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Loop through batches\n",
    "for i in range(num_batches):\n",
    "    print(f\"Processing batch {i+1}/{num_batches}...\")\n",
    "\n",
    "    # Get batch indices\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "\n",
    "    # Extract batch\n",
    "    X_batch = X_sampled[start_idx:end_idx]\n",
    "    y_batch = y_sampled[start_idx:end_idx]\n",
    "\n",
    "    # Train-test split for this batch\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train TabPFN\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "    \n",
    "    \n",
    "print(accuracy_score(all_y_true, all_y_pred))\n",
    "print(metrics.confusion_matrix(all_y_pred, all_y_true))\n",
    "print(classification_report(all_y_pred, all_y_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
